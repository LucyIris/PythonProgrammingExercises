{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8: Pair Programming - Optimisation in SciPy\n",
    "\n",
    "### Task A: Function fitting\n",
    "\n",
    "Consider an electronic device that takes an input voltage $x$. We measure the output voltage as $y$ using a voltmeter. However, this voltmeter is noisy! \n",
    "\n",
    "We would like to model the behaviour of the device. We do this by taking $n$ output measurements for multiple input voltages. For inputs $[x_0, x_1, x_2 ... x_{n-1}]^T$ our voltmeter gives outputs $[y_0, y_1, y_2 ... y_{n-1}]^T$. These measurements are given in the code block below as NumPy arrays `x` and `y`.\n",
    "\n",
    "Let's assume the relationship between the output and input of the device is linear. We can model the device using\n",
    "\n",
    "$$ z_i = f(x_i,\\theta_0, \\theta_1) = \\theta_0 + \\theta_1 x_i $$\n",
    "\n",
    "where $z_i$ is the model's prediction of an output $y_i$. $\\theta_0$ and $\\theta_1$ are the *learnable parameters* of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "x = np.linspace(0,1,10)\n",
    "\n",
    "y = np.array([1.22647365, 1.14187619, 1.30387096, 1.17376336, 1.26089758, 1.44926985,\n",
    " 1.43433494, 1.62252649, 1.87298459, 2.0802078 ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A1.** Produce a scatter plot of `y` against `x`. Briefly discuss why it isn't feasible to treat learning the model's parameters as a root-finding problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A2.** Learn $\\theta_0$ and $\\theta_1$ by minimising a loss function that is the sum of the squared differences between our predictions and our actual measurements: $$\\sum_{n=0}^{n-1} (z_i - y_i)^2$$\n",
    "\n",
    "Do this by using the Newton-CG algorithm (see https://docs.scipy.org/doc/scipy/reference/optimize.minimize-newtoncg.html#optimize-minimize-newtoncg).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A3.** Plot your model of the device alongside the actual data. Is this a good fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A4.** Adjust your code so that it is possible to model the voltmeter as a second order polynomial. This has **three** learnable parameters. Learn these using the Nelder-Mead algorithm https://docs.scipy.org/doc/scipy/reference/optimize.minimize-neldermead.html and comment on the fit. Note that the Nelder-Mead algorithm does not require you to supply a Jacobian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A5.** As there are 10 data points (each $x_i$, $y_i$ pair), we are able to exactly fit our data using a ninth order polynomial. We can write\n",
    "\n",
    "$$ \\mathbf{y} = \\mathbf{X}\\Theta$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    y_0 \\\\\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    y_9 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "    1 & x_0 & x_0{^2} & \\dots & x_0{^9} \\\\\n",
    "    1 & x_1 & x_1{^2} & \\dots & x_1{^9} \\\\\n",
    "    1 & x_2 & x_2{^2} & \\dots & x_2{^9} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots&\\vdots  \\\\\n",
    "    1 & x_9 & x_9{^2} & \\dots & x_9{^9} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    \\theta_0 \\\\\n",
    "    \\theta_1 \\\\\n",
    "    \\theta_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\theta_9\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Calculate $\\Theta$ using these 10 data points. Then, plot the resulting model for a new array of inputs `x = np.linspace(0,1,100)`. Comment on whether this model is useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task B: Constrained Optimisation\n",
    "\n",
    "Consider the Booth function $$ f(x, y) = (x+2y-7)^2 + (2x + y-5)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B1.** Draw a contour plot of this function for  $-10 \\leq x, y\\leq 10$. Can you work out where the minimum is from this plot?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B2.** Starting with ($x_0=5, y_0=-2$) Use the Newton-CG algorithm to find the minimum of this function. What is the function value at this minimum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B3:**. We would like to minimise the Booth function, but also penalise large magnitudes of $x$ and $y$. Devise a new loss function to achieve this, and minimise this new loss function using the Newton-CG algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B4.** Modify your new loss function to weight the magnitude penalty term by a user-defined constant $\\lambda$. Minimise this loss function for increasing values of $\\lambda$ and comment on how the solution changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B5:** The magnitude penalties we placed on $x$ and $y$ were soft constraints. Now consider an optimisation scenario with hard constraints. That is, we want to minimise the Booth function subject to $ x < 0.5$, $y < 5$. Use the Trust region algorithm to achieve this (https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#trust-region-constrained-algorithm-method-trust-constr).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B6.** Plot these hard constraints as lines on your contour plot and confirm that your solution is sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
